{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Coding Exercise 3: Encoding Categorical Data for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Instructions:\n",
    "\n",
    "- Import required libraries - Pandas, Numpy, and required classes for this task - ColumnTransformer, OneHotEncoder, LabelEncoder.\n",
    "\n",
    "- Start by loading the Titanic dataset into a pandas data frame. This can be done using the pd.read_csv function. The dataset's name is 'titanic.csv'.\n",
    "\n",
    "- Identify the categorical features in your dataset that need to be encoded. You can store these feature names in a list for easy access later.\n",
    "\n",
    "- To apply OneHotEncoding to these categorical features, create an instance of the ColumnTransformer class. Make sure to pass the OneHotEncoder() as an argument along with the list of categorical features.\n",
    "\n",
    "- Use the fit_transform method on the instance of ColumnTransformer to apply the OneHotEncoding.\n",
    "\n",
    "- The output of the fit_transform method should be converted into a NumPy array for further use.\n",
    "\n",
    "- The 'Survived' column in your dataset is the dependent variable. This is a binary categorical variable that should be encoded using LabelEncoder.\n",
    "\n",
    "- Print the updated matrix of features and the dependent variable vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37puETfgRzzg",
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EoRP98MpR-qj"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-qiINBQSK2g"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RopL7tUZSQkT"
   },
   "source": [
    "## Importing the dataset\n",
    "In order to use the same dataset in the udemy dataset, I need to drop Age and Cabin null data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwEPNDWySTKm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset: https://github.com/datasciencedojo/datasets/blob/master/titanic.csv\n",
    "dataset = pd.read_csv('titanic.csv')\n",
    "\n",
    "# cabin_not_null = dataset[dataset['Cabin'].notnull()]  # Only Cabin null data\n",
    "dataset = dataset.dropna(subset=['Age', 'Cabin'])\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhfKXNxlSabC"
   },
   "source": [
    "## Identify the categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c93k7ipkSexq"
   },
   "outputs": [],
   "source": [
    "categorical_features = ['Sex', 'Embarked', 'Pclass']  # Assuming these are the categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement an instance of the ColumnTransformer class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder', OneHotEncoder(), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through any other columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the fit_transform method on the instance of ColumnTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ct.fit_transform(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the output into a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use LabelEncoder to encode binary categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(dataset['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the updated matrix of features and the dependent variable vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated matrix of features (after OneHotEncoding):\n",
      " [[1.0 0.0 1.0 ... 'PC 17599' 71.2833 'C85']\n",
      " [1.0 0.0 0.0 ... '113803' 53.1 'C123']\n",
      " [0.0 1.0 0.0 ... '17463' 51.8625 'E46']\n",
      " ...\n",
      " [1.0 0.0 1.0 ... '11767' 83.1583 'C50']\n",
      " [1.0 0.0 0.0 ... '112053' 30.0 'B42']\n",
      " [0.0 1.0 1.0 ... '111369' 30.0 'C148']]\n",
      "Dependent variable vector (encoded using LabelEncoder):\n",
      " [1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1\n",
      " 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1]\n",
      "missnig data PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Updated matrix of features (after OneHotEncoding):\\n\", X)\n",
    "print(\"Dependent variable vector (encoded using LabelEncoder):\\n\", y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missnig data:\n",
      " PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       2\n",
      "dtype: int64\n",
      "\n",
      " False\n",
      "(185, 18)\n",
      "(185,)\n"
     ]
    }
   ],
   "source": [
    "missing_data = dataset.isnull().sum()\n",
    "print(\"Missnig data:\\n\", missing_data )\n",
    "\n",
    "print(\"\\n\",np.array_equal(X, y))\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_preprocessing_tools.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
